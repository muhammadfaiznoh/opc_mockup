services:
  data_generator:
    build:
        dockerfile: ./container/datagenerator/Dockerfile
    entrypoint: 
      - python
      - ./opc_data_generator.py
    container_name: opc_data_generator
    restart: on-failure
    # expose:
    #   - "4840"
    ports:
      - "4840:4840"

  zookeeper:
    image: confluentinc/cp-zookeeper:5.3.1
    container_name: zookeeper
    hostname: zookeeper
    ports:
    - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
  kafka:
    image: confluentinc/cp-kafka:5.3.1
    container_name: kafka
    hostname: kafka
    ports:
    - "9092:9092"
    # expose:
    # - "9092"
    restart: always
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
    - zookeeper

  opc_producer:
    build:
        dockerfile: ./container/opc/Dockerfile
    entrypoint: 
      - python
      - ./opc_producer.py
    container_name: opc_producer
    restart: always
    depends_on:
      - kafka

  opc_consumer:
    build:
        dockerfile: ./container/opc/Dockerfile
    entrypoint: 
      - python
      - ./opc_streaming.py
    container_name: opc_consumer
    restart: always
    depends_on:
      - kafka

networks:
  mockup_network:
    driver: host
    name: mockup_network